{"id":"table","metadata":{"name":null,"description":null},"methods":[{"metadata":{"constructor":false,"name":"Table","source":"/lib/bigquery/table.js#L56","description":"<p>Table objects are returned by methods such as <a data-custom-type=\"bigquery/dataset#table\"></a>, <a data-custom-type=\"bigquery/dataset#createTable\"></a>, and <a data-custom-type=\"bigquery/dataset#getTables\"></a>.</p>","examples":[],"resources":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"constructor":false,"name":"copy","source":"/lib/bigquery/table.js#L140","description":"<p>Copy data from one table to another, optionally creating that table.</p>","examples":[{"code":"table.copy(dataset.table('institution_data'), function(err, job) {});"},{"caption":"<p>See the [<code>configuration.copy</code>](http://goo.gl/dKWIyS) object for all \navailable options.</p>","code":"var metadata = {\n  createDisposition: 'CREATE_NEVER',\n  writeDisposition: 'WRITE_TRUNCATE'\n};\n\ntable.copy(options, metadata, function(err, job) {});"}],"resources":[]},"params":[{"name":"destination","description":"- The destination table.","types":["<a data-custom-type=\"bigquery\"></a>","table"]},{"name":"metadata","description":"- Metadata to set with the copy operation. The metadata object should be in the format of the [<code>configuration.copy</code>](http://goo.gl/dKWIyS) property of a Jobs resource.","types":["object="]},{"name":"callback","description":"- The callback function. ","types":["function"]}],"exceptions":[{"type":"Error","description":"If a destination other than a Table object is provided. "}],"returns":[]},{"metadata":{"constructor":false,"name":"createReadStream","source":"/lib/bigquery/table.js#L196","description":"<p>Create a readable stream of the rows of data in your table.</p>","examples":[{"code":"var through2 = require('through2');\n\ntable.createReadStream()\n  .pipe(through2.obj(function(row, enc, next) {\n    this.push(JSON.stringify(row) + '\\n');\n  }))\n  .pipe(fs.createWriteStream('./institutions.json'));"}],"resources":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"constructor":false,"name":"createWriteStream","source":"/lib/bigquery/table.js#L268","description":"<p>Load data into your table from a readable stream of JSON or CSV-formatted data.</p>","examples":[{"caption":"<p>Load data from a CSV file.</p>","code":"var request = require('request');\n\nvar csvUrl = 'http://goo.gl/kSE7z6';\n\nvar metadata = {\n  allowJaggedRows: true,\n  skipLeadingRows: 1\n};\n\nrequest.get(csvUrl)\n  .pipe(table.createWriteStream(metadata))\n  .on('complete', function(job) {\n    // job is a Job object, which you can use to check the status of the load\n    // operation.\n    job.getMetadata(function(err, metadata) {\n      // metadata.status\n    });\n  });"},{"caption":"<p>Load data from a JSON file.</p>","code":"var fs = require('fs');\n\nfs.createReadStream('./institutions.json')\n  .pipe(table.createWriteStream('json'))\n  .on('complete', function(job) {});"}],"resources":[]},"params":[{"name":"metadata","description":"- Metadata to set with the load operation. The metadata object should be in the format of the [<code>configuration.load</code>](http://goo.gl/BVcXk4) property of a Jobs resource. If a string is given, it will be used as the filetype.","types":["string","object="]}],"exceptions":[{"type":"Error","description":"If source format isn't recognized. "}],"returns":[]},{"metadata":{"constructor":false,"name":"delete","source":"/lib/bigquery/table.js#Lundefined","description":"<p>Delete a table and all its data.</p>","examples":[{"code":"table.delete(function(err) {});"}],"resources":[]},"params":[{"name":"callback","description":"- The callback function. ","types":["function"]}],"exceptions":[],"returns":[]},{"metadata":{"constructor":false,"name":"export","source":"/lib/bigquery/table.js#Lundefined","description":"<p>Export table to Google Cloud Storage.</p>","examples":[{"code":"var exportedFile = storage.bucket('institutions').file('2014.csv');"},{"caption":"<p>To use the default options, just pass a <a data-custom-type=\"storage/file\"></a> object. \nNote: The exported format type will be inferred by the file's extension. \nIf you wish to override this, or provide an array of destination files, \nyou must provide an <code>options</code> object.</p>","code":"table.export(exportedFile, function(err, job) {});"},{"caption":"<p>If you need more customization, pass an <code>options</code> object.</p>","code":"var options = {\n  format: 'json',\n  gzip: true\n};\n\ntable.export(exportedFile, options, function(err, job) {});"},{"caption":"<p>You can also specify multiple destination files.</p>","code":"table.export([\n  storage.bucket('institutions').file('2014.json'),\n  storage.bucket('institutions-copy').file('2014.json')\n], options, function(err, job) {});"}],"resources":[]},"params":[{"name":"destination","description":"- Where the file should be exported to.","types":["<a data-custom-type=\"storage\"></a>","file","<a data-custom-type=\"storage\"></a>","file[]"]},{"name":"options","description":"- The configuration object.","types":["object="]},{"name":"options.format","description":"- The format to export the data in. Allowed options are \"CSV\", \"JSON\", or \"AVRO\". Default: \"CSV\".","types":["string"]},{"name":"options.gzip","description":"- Specify if you would like the file compressed with GZIP. Default: false.","types":["boolean"]},{"name":"callback","description":"- The callback function. ","types":["function"]}],"exceptions":[{"type":"Error","description":"If destination isn't a File object."},{"type":"Error","description":"If destination format isn't recongized. "}],"returns":[]},{"metadata":{"constructor":false,"name":"getMetadata","source":"/lib/bigquery/table.js#L469","description":"<p>Return the metadata associated with the Table.</p>","examples":[{"code":"table.getMetadata(function(err, metadata) {});"}],"resources":[]},"params":[{"name":"callback","description":"- The callback function. ","types":["function"]}],"exceptions":[],"returns":[]},{"metadata":{"constructor":false,"name":"getRows","source":"/lib/bigquery/table.js#L504","description":"<p>Retrieves table data from a specified set of rows. The rows are returned to your callback as an array of objects matching your table&#39;s schema.</p>","examples":[{"code":"var options = {\n  maxResults: 100\n};\n\ntable.getRows(options, function(err, rows, nextQuery) {\n  // If `nextQuery` is non-null, there are more results to fetch.\n  if (nextQuery) {\n    table.getRows(nextQuery, function(err, rows, nextQuery) {});\n  }\n});`"}],"resources":[]},"params":[{"name":"options","description":"- The configuration object.","types":["object="]},{"name":"options.maxResults","description":"- Maximum number of results to return.","types":["number"]},{"name":"callback","description":"- The callback function. ","types":["function"]}],"exceptions":[],"returns":[]},{"metadata":{"constructor":false,"name":"import","source":"/lib/bigquery/table.js#L607","description":"<p>Load data from a local file or Storage file (<a data-custom-type=\"storage/file\"></a>).</p><p>By loading data this way, you create a load job that will run your data load asynchronously. If you would like instantaneous access to your data, insert it using <a data-custom-type=\"bigquery/table#insert\"></a>.</p><p>Note: Only JSON and CSV source files are supported. The file type will be inferred by the given file&#39;s extension. If you wish to override this, you must provide a <code>metadata</code> object.</p>","examples":[{"caption":"<p>Load data from a local file.</p>","code":"table.import('./institutions.csv', function(err, job) {});"},{"caption":"<p>You may also pass in metadata in the format of a Jobs resource. See \n(http://goo.gl/BVcXk4) for a full list of supported values.</p>","code":"var metadata = {\n  encoding: 'ISO-8859-1',\n  sourceFormat: 'JSON'\n};\n\ntable.import('./institutions.csv', metadata, function(err, job) {});"},{"caption":"<p>Load data from a file in your Storage bucket.</p>","code":"var data = storage.bucket('institutions').file('data.csv');\ntable.import(data, function(err, job) {});"},{"caption":"<p>Load data from multiple files in your Storage bucket(s).</p>","code":"table.import([\n  storage.bucket('institutions').file('2011.csv'),\n  storage.bucket('institutions').file('2012.csv')\n], function(err, job) {});"}],"resources":[]},"params":[{"name":"source","description":"- The source file to import.","types":["string","<a data-custom-type=\"storage\"></a>","file"]},{"name":"metadata","description":"- Metadata to set with the load operation. The metadata object should be in the format of the [<code>configuration.load</code>](http://goo.gl/BVcXk4) property of a Jobs resource.","types":["object="]},{"name":"callback","description":"- The callback function. ","types":["function"]}],"exceptions":[{"type":"Error","description":"If the source isn't a string file name or a File instance. "}],"returns":[]},{"metadata":{"constructor":false,"name":"insert","source":"/lib/bigquery/table.js#Lundefined","description":"<p>Stream data into BigQuery one record at a time without running a load job.</p><p>There are more strict quota limits using this method so it is highly recommended that you load data into BigQuery using <a data-custom-type=\"bigquery/table#import\"></a> instead.</p>","examples":[{"caption":"<p>Insert a single row.</p>","code":"table.insert({\n  INSTNM: 'Motion Picture Institute of Michigan',\n  CITY: 'Troy',\n  STABBR: 'MI'\n}, insertHandler);"},{"caption":"<p>Insert multiple rows at a time.</p>","code":"var rows = [\n  {\n    INSTNM: 'Motion Picture Institute of Michigan',\n    CITY: 'Troy',\n    STABBR: 'MI'\n  },\n  // ...\n];\n\ntable.insert(rows, insertHandler);"},{"caption":"<p>Handling the response.</p>","code":"function insertHandler(err, insertErrors) {\n  // err (object):\n  //   An API error occurred.\n\n  // insertErrors (object[]):\n  //   If populated, some rows failed to insert, while others may have\n  //   succeeded.\n  //\n  // insertErrors[].row (original individual row object passed to `insert`)\n  // insertErrors[].errors[].reason\n  // insertErrors[].errors[].message\n\n  // See https://developers.google.com/bigquery/troubleshooting-errors for\n  // recommendations on handling errors.\n}"}],"resources":[]},"params":[{"name":"rows","description":"- The rows to insert into the table.","types":["object","object[]"]},{"name":"callback","description":"- The callback function. ","types":["function"]}],"exceptions":[],"returns":[]},{"metadata":{"constructor":false,"name":"query","source":"/lib/bigquery/table.js#Lundefined","description":"<p>Run a query scoped to your dataset.</p><p>See <a data-custom-type=\"bigquery#query\"></a> for full documentation of this method.</p>","examples":[],"resources":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"constructor":false,"name":"setMetadata","source":"/lib/bigquery/table.js#Lundefined","description":"<p>Set the metadata on the table.</p>","examples":[],"resources":[]},"params":[{"name":"metadata","description":"- The metadata key/value object to set.","types":["object"]},{"name":"metadata.description","description":"- A user-friendly description of the table.","types":["string"]},{"name":"metadata.name","description":"- A descriptive name for the table.","types":["string"]},{"name":"metadata.schema","description":"- A comma-separated list of name:type pairs. Valid types are \"string\", \"integer\", \"float\", \"boolean\", and \"timestamp\". If the type is omitted, it is assumed to be \"string\". Example: \"name:string, age:integer\". Schemas can also be specified as a JSON array of fields, which allows for nested and repeated fields. See a [Table resource](http://goo.gl/sl8Dmg) for more detailed information.","types":["string","object"]},{"name":"callback","description":"- The callback function.","types":["function"]}],"exceptions":[],"returns":[]}]}