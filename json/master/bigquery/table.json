[
  {
    "tags": [],
    "description": {
      "full": "<p>Copyright 2014 Google Inc. All Rights Reserved.</p><p>Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);<br />you may not use this file except in compliance with the License.<br />You may obtain a copy of the License at</p><pre><code> http://www.apache.org/licenses/LICENSE-2.0\n</code></pre><p>Unless required by applicable law or agreed to in writing, software<br />distributed under the License is distributed on an &quot;AS IS&quot; BASIS,<br />WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br />See the License for the specific language governing permissions and<br />limitations under the License.</p>",
      "summary": "<p>Copyright 2014 Google Inc. All Rights Reserved.</p>",
      "body": "<p>Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);<br />you may not use this file except in compliance with the License.<br />You may obtain a copy of the License at</p><pre><code> http://www.apache.org/licenses/LICENSE-2.0\n</code></pre><p>Unless required by applicable law or agreed to in writing, software<br />distributed under the License is distributed on an &quot;AS IS&quot; BASIS,<br />WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br />See the License for the specific language governing permissions and<br />limitations under the License.</p>"
    },
    "isPrivate": false,
    "isConstructor": false,
    "isEvent": false,
    "ignore": true,
    "line": 1,
    "codeStart": 16
  },
  {
    "tags": [
      {
        "type": "module",
        "string": "bigquery/table"
      }
    ],
    "description": {
      "full": "",
      "summary": "",
      "body": ""
    },
    "isPrivate": false,
    "isConstructor": false,
    "isEvent": false,
    "ignore": true,
    "line": 17,
    "codeStart": 21,
    "code": "'use strict';\n\nvar crypto = require('crypto');\nvar duplexify = require('duplexify');\nvar extend = require('extend');\nvar fs = require('fs');\nvar path = require('path');\nvar streamEvents = require('stream-events');\nvar through = require('through2');"
  },
  {
    "tags": [
      {
        "type": "type",
        "types": [
          "module:storage/file"
        ],
        "typesDescription": "module:<a href=\"module%3Astorage%2Ffile.html\">storage/file</a>",
        "optional": false,
        "nullable": false,
        "nonNullable": false,
        "variable": false
      },
      {
        "type": "private",
        "visibility": "private"
      }
    ],
    "description": {
      "full": "",
      "summary": "",
      "body": ""
    },
    "isPrivate": true,
    "isConstructor": false,
    "isEvent": false,
    "ignore": false,
    "line": 31,
    "codeStart": 35,
    "code": "var File = require('../storage/file');",
    "ctx": {
      "type": "declaration",
      "name": "File",
      "value": "require('../storage/file')",
      "string": "File"
    }
  },
  {
    "tags": [
      {
        "type": "type",
        "types": [
          "module:common/util"
        ],
        "typesDescription": "module:<a href=\"module%3Acommon%2Futil.html\">common/util</a>",
        "optional": false,
        "nullable": false,
        "nonNullable": false,
        "variable": false
      },
      {
        "type": "private",
        "visibility": "private"
      }
    ],
    "description": {
      "full": "",
      "summary": "",
      "body": ""
    },
    "isPrivate": true,
    "isConstructor": false,
    "isEvent": false,
    "ignore": false,
    "line": 37,
    "codeStart": 41,
    "code": "var util = require('../common/util');",
    "ctx": {
      "type": "declaration",
      "name": "util",
      "value": "require('../common/util')",
      "string": "util"
    }
  },
  {
    "tags": [
      {
        "type": "param",
        "name": "dataset",
        "description": "<ul>\n<li>Dataset instance.</li>\n</ul>\n",
        "types": [
          "module:bigquery/dataset"
        ],
        "typesDescription": "module:<a href=\"module%3Abigquery%2Fdataset.html\">bigquery/dataset</a>",
        "optional": false,
        "nullable": false,
        "nonNullable": false,
        "variable": false
      },
      {
        "type": "param",
        "name": "id",
        "description": "<ul>\n<li>The ID of the table.</li>\n</ul>\n",
        "types": [
          "string"
        ],
        "typesDescription": "<code>string</code>",
        "optional": false,
        "nullable": false,
        "nonNullable": false,
        "variable": false
      }
    ],
    "description": {
      "full": "<p>Developer Documentation</p>",
      "summary": "<p>Developer Documentation</p>",
      "body": ""
    },
    "isPrivate": false,
    "isConstructor": false,
    "isEvent": false,
    "ignore": true,
    "line": 43,
    "codeStart": 48
  },
  {
    "tags": [
      {
        "type": "alias",
        "string": "module:bigquery/table"
      },
      {
        "type": "constructor",
        "string": ""
      }
    ],
    "description": {
      "full": "<p>Table objects are returned by methods such as<br />{module:bigquery/dataset#table}, {module:bigquery/dataset#createTable}, and<br />{module:bigquery/dataset#getTables}.</p>",
      "summary": "<p>Table objects are returned by methods such as<br />{module:bigquery/dataset#table}, {module:bigquery/dataset#createTable}, and<br />{module:bigquery/dataset#getTables}.</p>",
      "body": ""
    },
    "isPrivate": false,
    "isConstructor": true,
    "isEvent": false,
    "ignore": false,
    "line": 48,
    "codeStart": 56,
    "code": "function Table(dataset, id) {\n  this.bigQuery = dataset.bigQuery;\n  this.dataset = dataset;\n  this.id = id;\n  this.metadata = {};\n}",
    "ctx": {
      "type": "constructor",
      "name": "Table",
      "string": "Table()"
    }
  },
  {
    "tags": [
      {
        "type": "static",
        "string": ""
      },
      {
        "type": "private",
        "visibility": "private"
      },
      {
        "type": "param",
        "name": "str",
        "description": "<ul>\n<li>Comma-separated schema string.</li>\n</ul>\n",
        "types": [
          "string"
        ],
        "typesDescription": "<code>string</code>",
        "optional": false,
        "nullable": false,
        "nonNullable": false,
        "variable": false
      },
      {
        "type": "return",
        "types": [
          "object"
        ],
        "typesDescription": "<code>object</code>",
        "optional": false,
        "nullable": false,
        "nonNullable": false,
        "variable": false,
        "description": "<p>Table schema in the format the API expects.</p>"
      }
    ],
    "description": {
      "full": "<p>Convert a comma-separated name:type string to a table schema object.</p>",
      "summary": "<p>Convert a comma-separated name:type string to a table schema object.</p>",
      "body": ""
    },
    "isPrivate": true,
    "isConstructor": false,
    "isEvent": false,
    "ignore": false,
    "line": 63,
    "codeStart": 72,
    "code": "Table.createSchemaFromString_ = function(str) {\n  return str.split(/\\s*,\\s*/).reduce(function(acc, pair) {\n    acc.fields.push({\n      name: pair.split(':')[0],\n      type: pair.split(':')[1] || 'string'\n    });\n\n    return acc;\n  }, {\n    fields: []\n  });\n};",
    "ctx": {
      "type": "method",
      "receiver": "Table",
      "name": "createSchemaFromString_",
      "string": "Table.createSchemaFromString_()"
    }
  },
  {
    "tags": [
      {
        "type": "static",
        "string": ""
      },
      {
        "type": "private",
        "visibility": "private"
      },
      {
        "type": "param",
        "name": "schema",
        "description": "",
        "types": [
          "object"
        ],
        "typesDescription": "<code>object</code>",
        "optional": false,
        "nullable": false,
        "nonNullable": false,
        "variable": false
      },
      {
        "type": "param",
        "name": "rows",
        "description": "",
        "types": [
          "array"
        ],
        "typesDescription": "<code>array</code>",
        "optional": false,
        "nullable": false,
        "nonNullable": false,
        "variable": false
      },
      {
        "type": "return",
        "types": [
          "array"
        ],
        "typesDescription": "<code>array</code>",
        "optional": false,
        "nullable": false,
        "nonNullable": false,
        "variable": false,
        "description": "<p>Fields using their matching names from the table&#39;s schema.</p>"
      }
    ],
    "description": {
      "full": "<p>Merge a rowset returned from the API with a table schema.</p>",
      "summary": "<p>Merge a rowset returned from the API with a table schema.</p>",
      "body": ""
    },
    "isPrivate": true,
    "isConstructor": false,
    "isEvent": false,
    "ignore": false,
    "line": 85,
    "codeStart": 95,
    "code": "Table.mergeSchemaWithRows_ = function(schema, rows) {\n  return rows.map(mergeSchema).map(flattenRows);\n\n  function mergeSchema(row) {\n    return row.f.map(function(field, index) {\n      var fieldObject = {};\n      fieldObject[schema.fields[index].name] = field.v;\n      return fieldObject;\n    });\n  }\n\n  function flattenRows(rows) {\n    return rows.reduce(function(acc, row) {\n      var key = Object.keys(row)[0];\n      acc[key] = row[key];\n      return acc;\n    }, {});\n  }\n};",
    "ctx": {
      "type": "method",
      "receiver": "Table",
      "name": "mergeSchemaWithRows_",
      "string": "Table.mergeSchemaWithRows_()"
    }
  },
  {
    "tags": [
      {
        "type": "param",
        "name": "destination",
        "description": "<ul>\n<li>The destination table.</li>\n</ul>\n",
        "types": [
          "module:bigquery/table"
        ],
        "typesDescription": "module:<a href=\"module%3Abigquery%2Ftable.html\">bigquery/table</a>",
        "optional": false,
        "nullable": false,
        "nonNullable": false,
        "variable": false
      },
      {
        "type": "param",
        "name": "metadata",
        "description": "<ul>\n<li>Metadata to set with the copy operation. The     metadata object should be in the format of the<br />  <a href=\"http://goo.gl/dKWIyS\"><code>configuration.copy</code></a> property of a Jobs resource.</li>\n</ul>\n",
        "types": [
          "object"
        ],
        "typesDescription": "<code>object</code>|<code>undefined</code>",
        "optional": true,
        "nullable": false,
        "nonNullable": false,
        "variable": false
      },
      {
        "type": "param",
        "name": "callback",
        "description": "<ul>\n<li>The callback function. </li>\n</ul>\n",
        "types": [
          "function"
        ],
        "typesDescription": "<code>function</code>",
        "optional": false,
        "nullable": false,
        "nonNullable": false,
        "variable": false
      },
      {
        "type": "throws",
        "types": [
          "Error"
        ],
        "description": "<p>If a destination other than a Table object is provided. </p>"
      },
      {
        "type": "example",
        "string": "table.copy(dataset.table('institution_data'), function(err, job) {});\n\n//-\n// See the [`configuration.copy`](http://goo.gl/dKWIyS) object for all\n// available options.\n//-\nvar metadata = {\n  createDisposition: 'CREATE_NEVER',\n  writeDisposition: 'WRITE_TRUNCATE'\n};\n\ntable.copy(options, metadata, function(err, job) {});"
      }
    ],
    "description": {
      "full": "<p>Copy data from one table to another, optionally creating that table.</p>",
      "summary": "<p>Copy data from one table to another, optionally creating that table.</p>",
      "body": ""
    },
    "isPrivate": false,
    "isConstructor": false,
    "isEvent": false,
    "ignore": false,
    "line": 115,
    "codeStart": 140,
    "code": "Table.prototype.copy = function(destination, metadata, callback) {\n  var that = this;\n\n  if (!(destination instanceof Table)) {\n    throw new Error('Destination must be a Table object.');\n  }\n\n  if (util.is(metadata, 'function')) {\n    callback = metadata;\n    metadata = {};\n  }\n\n  var body = {\n    configuration: {\n      copy: extend(true, metadata || {}, {\n        destinationTable: {\n          datasetId: destination.dataset.id,\n          projectId: destination.bigQuery.projectId,\n          tableId: destination.id\n        },\n        sourceTable: {\n          datasetId: this.dataset.id,\n          projectId: this.bigQuery.projectId,\n          tableId: this.id\n        }\n      })\n    }\n  };\n\n  this.bigQuery.makeReq_('POST', '/jobs', null, body, function(err, resp) {\n    if (err) {\n      callback(err);\n      return;\n    }\n\n    var job = that.bigQuery.job(resp.jobReference.jobId);\n    job.metadata = resp;\n\n    callback(null, job);\n  });\n};",
    "ctx": {
      "type": "method",
      "constructor": "Table",
      "cons": "Table",
      "name": "copy",
      "string": "Table.prototype.copy()"
    }
  },
  {
    "tags": [
      {
        "type": "return",
        "types": [
          "ReadStream"
        ],
        "typesDescription": "<a href=\"ReadStream.html\">ReadStream</a>",
        "optional": false,
        "nullable": false,
        "nonNullable": false,
        "variable": false,
        "description": ""
      },
      {
        "type": "example",
        "string": "var through2 = require('through2');\n\ntable.createReadStream()\n  .pipe(through2.obj(function(row, enc, next) {\n    this.push(JSON.stringify(row) + '\\n');\n  }))\n  .pipe(fs.createWriteStream('./institutions.json'));"
      }
    ],
    "description": {
      "full": "<p>Create a readable stream of the rows of data in your table.</p>",
      "summary": "<p>Create a readable stream of the rows of data in your table.</p>",
      "body": ""
    },
    "isPrivate": false,
    "isConstructor": false,
    "isEvent": false,
    "ignore": false,
    "line": 182,
    "codeStart": 196,
    "code": "Table.prototype.createReadStream = function() {\n  var that = this;\n\n  var stream = streamEvents(through.obj());\n  stream.once('reading', function() {\n    that.getRows(handleResponse);\n  });\n  return stream;\n\n  function handleResponse(err, rows, nextQuery) {\n    if (err) {\n      stream.emit('error', err);\n      stream.end();\n      return;\n    }\n\n    rows.forEach(function(row) {\n      stream.push(row);\n    });\n\n    if (nextQuery) {\n      that.getRows(nextQuery, handleResponse);\n    } else {\n      stream.end();\n    }\n  }\n};",
    "ctx": {
      "type": "method",
      "constructor": "Table",
      "cons": "Table",
      "name": "createReadStream",
      "string": "Table.prototype.createReadStream()"
    }
  },
  {
    "tags": [
      {
        "type": "param",
        "name": "metadata",
        "description": "<ul>\n<li>Metadata to set with the load operation.     The metadata object should be in the format of the<br />  <a href=\"http://goo.gl/BVcXk4\"><code>configuration.load</code></a> property of a Jobs resource.<br />  If a string is given, it will be used as the filetype.</li>\n</ul>\n",
        "types": [
          "string",
          "object"
        ],
        "typesDescription": "<code>string</code>|<code>object</code>|<code>undefined</code>",
        "optional": true,
        "nullable": false,
        "nonNullable": false,
        "variable": false
      },
      {
        "type": "return",
        "types": [
          "WriteStream"
        ],
        "typesDescription": "<a href=\"WriteStream.html\">WriteStream</a>",
        "optional": false,
        "nullable": false,
        "nonNullable": false,
        "variable": false,
        "description": ""
      },
      {
        "type": "throws",
        "types": [
          "Error"
        ],
        "description": "<p>If source format isn&#39;t recognized. </p>"
      },
      {
        "type": "example",
        "string": "//-\n// Load data from a CSV file.\n//-\nvar request = require('request');\n\nvar csvUrl = 'http://goo.gl/kSE7z6';\n\nvar metadata = {\n  allowJaggedRows: true,\n  skipLeadingRows: 1\n};\n\nrequest.get(csvUrl)\n  .pipe(table.createWriteStream(metadata))\n  .on('complete', function(job) {\n    // job is a Job object, which you can use to check the status of the load\n    // operation.\n    job.getMetadata(function(err, metadata) {\n      // metadata.status\n    });\n  });\n\n//-\n// Load data from a JSON file.\n//-\nvar fs = require('fs');\n\nfs.createReadStream('./institutions.json')\n  .pipe(table.createWriteStream('json'))\n  .on('complete', function(job) {});"
      }
    ],
    "description": {
      "full": "<p>Load data into your table from a readable stream of JSON or CSV-formatted<br />data.</p>",
      "summary": "<p>Load data into your table from a readable stream of JSON or CSV-formatted<br />data.</p>",
      "body": ""
    },
    "isPrivate": false,
    "isConstructor": false,
    "isEvent": false,
    "ignore": false,
    "line": 224,
    "codeStart": 268,
    "code": "Table.prototype.createWriteStream = function(metadata) {\n  var that = this;\n\n  metadata = metadata || {};\n\n  var fileTypeMap = {\n    csv: 'CSV',\n    json: 'NEWLINE_DELIMITED_JSON'\n  };\n  var fileTypes = Object.keys(fileTypeMap).map(function(key) {\n    return fileTypeMap[key];\n  });\n\n  if (util.is(metadata, 'string')) {\n    metadata = {\n      sourceFormat: fileTypeMap[metadata.toLowerCase()]\n    };\n  }\n\n  if (util.is(metadata.schema, 'string')) {\n    metadata.schema = Table.createSchemaFromString_(metadata.schema);\n  }\n\n  extend(true, metadata, {\n    destinationTable: {\n      projectId: that.bigQuery.projectId,\n      datasetId: that.dataset.id,\n      tableId: that.id\n    }\n  });\n\n  if (metadata.hasOwnProperty('sourceFormat') &&\n      fileTypes.indexOf(metadata.sourceFormat) < 0) {\n    throw new Error('Source format not recognized: ' + metadata.sourceFormat);\n  }\n\n  var dup = streamEvents(duplexify());\n\n  dup.once('writing', function() {\n    util.makeWritableStream(dup, {\n      makeAuthorizedRequest: that.bigQuery.makeAuthorizedRequest_,\n      metadata: {\n        configuration: {\n          load: metadata\n        }\n      },\n      request: {\n        uri: util.format('{base}/{projectId}/jobs', {\n          base: 'https://www.googleapis.com/upload/bigquery/v2/projects',\n          projectId: that.bigQuery.projectId\n        })\n      }\n    }, function(data) {\n      var job = that.bigQuery.job(data.jobReference.jobId);\n      job.metadata = data;\n\n      dup.emit('complete', job);\n      dup.end();\n    });\n  });\n\n  return dup;\n};\n\n/**\n * Delete a table and all its data.\n *\n * @param {function} callback - The callback function.\n *\n * @example\n * table.delete(function(err) {});\n */\nTable.prototype.delete = function(callback) {\n  this.makeReq_('DELETE', '', null, null, callback);\n};\n\n/**\n * Export table to Google Cloud Storage.\n *\n * @param {module:storage/file} destination - Where the file should be exported\n *     to.\n * @param {object=} options - The configuration object.\n * @param {string} options.format - The format to export the data in. Allowed\n *     options are \"CSV\", \"JSON\", or \"AVRO\". Default: \"CSV\".\n * @param {boolean} options.gzip - Specify if you would like the file compressed\n *     with GZIP. Default: false.\n * @param {function} callback - The callback function.\n *\n * @throws {Error} If destination isn't a File object.\n * @throws {Error} If destination format isn't recongized.\n *\n * @example\n * var exportedFile = storage.bucket('institutions').file('2014.csv');\n *\n * //-\n * // To use the default options, just pass a {module:storage/file} object.\n * //\n * // Note: The exported format type will be inferred by the file's extension.\n * // If you wish to override this, or provide an array of destination files,\n * // you must provide an `options` object.\n * //-\n * table.export(exportedFile, function(err, job) {});\n *\n * //-\n * // If you need more customization, pass an `options` object.\n * //-\n * var options = {\n *   format: 'json',\n *   gzip: true\n * };\n *\n * table.export(exportedFile, options, function(err, job) {});\n *\n * //-\n * // You can also specify multiple destination files.\n * //-\n * table.export([\n *   storage.bucket('institutions').file('2014.json'),\n *   storage.bucket('institutions-copy').file('2014.json')\n * ], options, function(err, job) {});\n */\nTable.prototype.export = function(destination, options, callback) {\n  var that = this;\n\n  if (util.is(options, 'function')) {\n    callback = options;\n    options = {};\n  }\n\n  var formats = {\n    avro: 'AVRO',\n    csv: 'CSV',\n    json: 'NEWLINE_DELIMITED_JSON'\n  };\n\n  extend(true, options, {\n    destinationUris: util.arrayize(destination).map(function(dest) {\n      if (!(dest instanceof File)) {\n        throw new Error('Destination must be a File object.');\n      }\n\n      // If no explicit format was provided, attempt to find a match from the\n      // file's extension. If no match, don't set, and default upstream to CSV.\n      var format = path.extname(dest.name).substr(1).toLowerCase();\n      if (!options.destinationFormat && !options.format && formats[format]) {\n        options.destinationFormat = formats[format];\n      }\n\n      return 'gs://' + dest.bucket.name + '/' + dest.name;\n    })\n  });\n\n  if (options.format) {\n    options.format = options.format.toLowerCase();\n\n    if (formats[options.format]) {\n      options.destinationFormat = formats[options.format];\n      delete options.format;\n    } else {\n      throw new Error('Destination format not recognized: ' + options.format);\n    }\n  }\n\n  if (options.gzip) {\n    options.compression = 'GZIP';\n    delete options.gzip;\n  }\n\n  var body = {\n    configuration: {\n      extract: extend(true, options, {\n        sourceTable: {\n          datasetId: this.dataset.id,\n          projectId: this.bigQuery.projectId,\n          tableId: this.id\n        }\n      })\n    }\n  };\n\n  this.bigQuery.makeReq_('POST', '/jobs', null, body, function(err, resp) {\n    if (err) {\n      callback(err);\n      return;\n    }\n\n    var job = that.bigQuery.job(resp.jobReference.jobId);\n    job.metadata = resp;\n\n    callback(null, job);\n  });\n};",
    "ctx": {
      "type": "method",
      "constructor": "Table",
      "cons": "Table",
      "name": "createWriteStream",
      "string": "Table.prototype.createWriteStream()"
    }
  },
  {
    "tags": [
      {
        "type": "param",
        "name": "callback",
        "description": "<ul>\n<li>The callback function. </li>\n</ul>\n",
        "types": [
          "function"
        ],
        "typesDescription": "<code>function</code>",
        "optional": false,
        "nullable": false,
        "nonNullable": false,
        "variable": false
      },
      {
        "type": "example",
        "string": "table.getMetadata(function(err, metadata) {});"
      }
    ],
    "description": {
      "full": "<p>Return the metadata associated with the Table.</p>",
      "summary": "<p>Return the metadata associated with the Table.</p>",
      "body": ""
    },
    "isPrivate": false,
    "isConstructor": false,
    "isEvent": false,
    "ignore": false,
    "line": 461,
    "codeStart": 469,
    "code": "Table.prototype.getMetadata = function(callback) {\n  var that = this;\n\n  this.makeReq_('GET', '', null, null, function(err, resp) {\n    if (err) {\n      callback(err);\n      return;\n    }\n\n    that.metadata = resp;\n\n    callback(null, that.metadata);\n  });\n};",
    "ctx": {
      "type": "method",
      "constructor": "Table",
      "cons": "Table",
      "name": "getMetadata",
      "string": "Table.prototype.getMetadata()"
    }
  },
  {
    "tags": [
      {
        "type": "param",
        "name": "options",
        "description": "<ul>\n<li>The configuration object.</li>\n</ul>\n",
        "types": [
          "object"
        ],
        "typesDescription": "<code>object</code>|<code>undefined</code>",
        "optional": true,
        "nullable": false,
        "nonNullable": false,
        "variable": false
      },
      {
        "type": "param",
        "name": "options.maxResults",
        "description": "<ul>\n<li>Maximum number of results to return.</li>\n</ul>\n",
        "types": [
          "number"
        ],
        "typesDescription": "<code>number</code>",
        "optional": false,
        "nullable": false,
        "nonNullable": false,
        "variable": false
      },
      {
        "type": "param",
        "name": "callback",
        "description": "<ul>\n<li>The callback function. </li>\n</ul>\n",
        "types": [
          "function"
        ],
        "typesDescription": "<code>function</code>",
        "optional": false,
        "nullable": false,
        "nonNullable": false,
        "variable": false
      },
      {
        "type": "example",
        "string": "var options = {\n  maxResults: 100\n};\n\ntable.getRows(options, function(err, rows, nextQuery) {\n  // If `nextQuery` is non-null, there are more results to fetch.\n  if (nextQuery) {\n    table.getRows(nextQuery, function(err, rows, nextQuery) {});\n  }\n});`"
      }
    ],
    "description": {
      "full": "<p>Retrieves table data from a specified set of rows. The rows are returned to<br />your callback as an array of objects matching your table&#39;s schema.</p>",
      "summary": "<p>Retrieves table data from a specified set of rows. The rows are returned to<br />your callback as an array of objects matching your table&#39;s schema.</p>",
      "body": ""
    },
    "isPrivate": false,
    "isConstructor": false,
    "isEvent": false,
    "ignore": false,
    "line": 484,
    "codeStart": 504,
    "code": "Table.prototype.getRows = function(options, callback) {\n  var that = this;\n\n  if (util.is(options, 'function')) {\n    callback = options;\n    options = {};\n  }\n\n  callback = callback || util.noop;\n\n  this.makeReq_('GET', '/data', options, null, function(err, resp) {\n    if (err) {\n      onComplete(err);\n      return;\n    }\n\n    var nextQuery = null;\n\n    if (resp.pageToken) {\n      nextQuery = extend({}, options, {\n        pageToken: resp.pageToken\n      });\n    }\n\n    if (resp.rows && resp.rows.length > 0 && !that.metadata.schema) {\n      // We don't know the schema for this table yet. Do a quick stat.\n      that.getMetadata(function(err) {\n        if (err) {\n          onComplete(err);\n          return;\n        }\n\n        onComplete(null, resp.rows, nextQuery);\n      });\n\n      return;\n    }\n\n    onComplete(null, resp.rows, nextQuery);\n  });\n\n  function onComplete(err, rows, nextQuery) {\n    if (err) {\n      callback(err);\n      return;\n    }\n\n    rows = Table.mergeSchemaWithRows_(that.metadata.schema, rows || []);\n\n    callback(null, rows, nextQuery);\n  }\n};",
    "ctx": {
      "type": "method",
      "constructor": "Table",
      "cons": "Table",
      "name": "getRows",
      "string": "Table.prototype.getRows()"
    }
  },
  {
    "tags": [
      {
        "type": "param",
        "name": "source",
        "description": "<ul>\n<li>The source file to import.</li>\n</ul>\n",
        "types": [
          "string",
          "module:storage/file"
        ],
        "typesDescription": "<code>string</code>|module:<a href=\"module%3Astorage%2Ffile.html\">storage/file</a>",
        "optional": false,
        "nullable": false,
        "nonNullable": false,
        "variable": false
      },
      {
        "type": "param",
        "name": "metadata",
        "description": "<ul>\n<li>Metadata to set with the load operation. The     metadata object should be in the format of the<br />  <a href=\"http://goo.gl/BVcXk4\"><code>configuration.load</code></a> property of a Jobs resource.</li>\n</ul>\n",
        "types": [
          "object"
        ],
        "typesDescription": "<code>object</code>|<code>undefined</code>",
        "optional": true,
        "nullable": false,
        "nonNullable": false,
        "variable": false
      },
      {
        "type": "param",
        "name": "callback",
        "description": "<ul>\n<li>The callback function. </li>\n</ul>\n",
        "types": [
          "function"
        ],
        "typesDescription": "<code>function</code>",
        "optional": false,
        "nullable": false,
        "nonNullable": false,
        "variable": false
      },
      {
        "type": "throws",
        "types": [
          "Error"
        ],
        "description": "<p>If the source isn&#39;t a string file name or a File instance. </p>"
      },
      {
        "type": "example",
        "string": "//-\n// Load data from a local file.\n//-\ntable.import('./institutions.csv', function(err, job) {});\n\n//-\n// You may also pass in metadata in the format of a Jobs resource. See\n// (http://goo.gl/BVcXk4) for a full list of supported values.\n//-\nvar metadata = {\n  encoding: 'ISO-8859-1',\n  sourceFormat: 'JSON'\n};\n\ntable.import('./institutions.csv', metadata, function(err, job) {});\n\n//-\n// Load data from a file in your Storage bucket.\n//-\nvar data = storage.bucket('institutions').file('data.csv');\ntable.import(data, function(err, job) {});\n\n//-\n// Load data from multiple files in your Storage bucket(s).\n//-\ntable.import([\n  storage.bucket('institutions').file('2011.csv'),\n  storage.bucket('institutions').file('2012.csv')\n], function(err, job) {});"
      }
    ],
    "description": {
      "full": "<p>Load data from a local file or Storage file ({module:storage/file}).</p><p>By loading data this way, you create a load job that will run your data load<br />asynchronously. If you would like instantaneous access to your data, insert<br />it using {module:bigquery/table#insert}.</p><p>Note: Only JSON and CSV source files are supported. The file type will be<br />inferred by the given file&#39;s extension. If you wish to override this, you<br />must provide a <code>metadata</code> object.</p>",
      "summary": "<p>Load data from a local file or Storage file ({module:storage/file}).</p>",
      "body": "<p>By loading data this way, you create a load job that will run your data load<br />asynchronously. If you would like instantaneous access to your data, insert<br />it using {module:bigquery/table#insert}.</p><p>Note: Only JSON and CSV source files are supported. The file type will be<br />inferred by the given file&#39;s extension. If you wish to override this, you<br />must provide a <code>metadata</code> object.</p>"
    },
    "isPrivate": false,
    "isConstructor": false,
    "isEvent": false,
    "ignore": false,
    "line": 557,
    "codeStart": 607,
    "code": "Table.prototype.import = function(source, metadata, callback) {\n  var that = this;\n\n  if (util.is(metadata, 'function')) {\n    callback = metadata;\n    metadata = {};\n  }\n\n  callback = callback || util.noop;\n  metadata = metadata || {};\n\n  var formats = {\n    csv: 'CSV',\n    json: 'NEWLINE_DELIMITED_JSON'\n  };\n\n  if (util.is(source, 'string')) {\n    // A path to a file was given. If a sourceFormat wasn't specified, try to\n    // find a match from the file's extension.\n    var format = formats[path.extname(source).substr(1).toLowerCase()];\n    if (!metadata.sourceFormat && format) {\n      metadata.sourceFormat = format;\n    }\n\n    // Read the file into a new write stream.\n    return fs.createReadStream(source)\n      .pipe(this.createWriteStream(metadata))\n      .on('error', callback)\n      .on('complete', callback);\n  }\n\n  var body = {\n    configuration: {\n      load: {\n        destinationTable: {\n          projectId: this.bigQuery.projectId,\n          datasetId: this.dataset.id,\n          tableId: this.id\n        }\n      }\n    }\n  };\n\n  extend(true, body.configuration.load, metadata, {\n    sourceUris: util.arrayize(source).map(function(src) {\n      if (!(src instanceof File)) {\n        throw new Error('Source must be a File object.');\n      }\n\n      // If no explicit format was provided, attempt to find a match from\n      // the file's extension. If no match, don't set, and default upstream\n      // to CSV.\n      var format = formats[path.extname(src.name).substr(1).toLowerCase()];\n      if (!metadata.sourceFormat && format) {\n        body.configuration.load.sourceFormat = format;\n      }\n\n      return 'gs://' + src.bucket.name + '/' + src.name;\n    })\n  });\n\n  this.bigQuery.makeReq_('POST', '/jobs', null, body, function(err, resp) {\n    if (err) {\n      callback(err);\n      return;\n    }\n\n    var job = that.bigQuery.job(resp.jobReference.jobId);\n    job.metadata = resp;\n\n    callback(null, job);\n  });\n};\n\n/**\n * Stream data into BigQuery one record at a time without running a load job.\n *\n * There are more strict quota limits using this method so it is highly\n * recommended that you load data into BigQuery using\n * {module:bigquery/table#import} instead.\n *\n * @param {object|object[]} rows - The rows to insert into the table.\n * @param {function} callback - The callback function.\n *\n * @example\n * //-\n * // Insert a single row.\n * //-\n * table.insert({\n *   INSTNM: 'Motion Picture Institute of Michigan',\n *   CITY: 'Troy',\n *   STABBR: 'MI'\n * }, insertHandler);\n *\n * //-\n * // Insert multiple rows at a time.\n * //-\n * var rows = [\n *   {\n *     INSTNM: 'Motion Picture Institute of Michigan',\n *     CITY: 'Troy',\n *     STABBR: 'MI'\n *   },\n *   // ...\n * ];\n *\n * table.insert(rows, insertHandler);\n *\n * //-\n * // Handling the response.\n * //-\n * function insertHandler(err, insertErrors) {\n *   // err (object):\n *   //   An API error occurred.\n *\n *   // insertErrors (object[]):\n *   //   If populated, some rows failed to insert, while others may have\n *   //   succeeded.\n *   //\n *   // insertErrors[].row (original individual row object passed to `insert`)\n *   // insertErrors[].errors[].reason\n *   // insertErrors[].errors[].message\n *\n *   // See https://developers.google.com/bigquery/troubleshooting-errors for\n *   // recommendations on handling errors.\n * }\n */\nTable.prototype.insert = function(rows, callback) {\n  var body = {\n    rows: util.arrayize(rows || []).map(function(row) {\n      var rowObject = {};\n      // Use the stringified contents of the row as a unique insert ID.\n      var md5 = crypto.createHash('md5');\n      md5.update(JSON.stringify(row));\n      rowObject.insertId = md5.digest('hex');\n      rowObject.json = row;\n      return rowObject;\n    })\n  };\n\n  this.makeReq_('POST', '/insertAll', null, body, function(err, resp) {\n    if (err) {\n      callback(err);\n      return;\n    }\n\n    var failedToInsert = (resp.insertErrors || []).map(function(insertError) {\n      return {\n        errors: insertError.errors.map(function(error) {\n          return {\n            message: error.message,\n            reason: error.reason\n          };\n        }),\n        row: body.rows[insertError.index].json\n      };\n    });\n\n    callback(null, failedToInsert);\n  });\n};\n\n/**\n * Run a query scoped to your dataset.\n *\n * See {module:bigquery#query} for full documentation of this method.\n */\nTable.prototype.query = function(query, callback) {\n  return this.dataset.query(query, callback);\n};\n\n/**\n * Set the metadata on the table.\n *\n * @param {object} metadata - The metadata key/value object to set.\n * @param {string} metadata.description - A user-friendly description of the\n *     table.\n * @param {string} metadata.name - A descriptive name for the table.\n * @param {string|object} metadata.schema - A comma-separated list of name:type\n *     pairs. Valid types are \"string\", \"integer\", \"float\", \"boolean\", and\n *     \"timestamp\". If the type is omitted, it is assumed to be \"string\".\n *     Example: \"name:string, age:integer\". Schemas can also be specified as a\n *     JSON array of fields, which allows for nested and repeated fields. See\n *     a [Table resource](http://goo.gl/sl8Dmg) for more detailed information.\n * @param {function} callback - The callback function.\n */\nTable.prototype.setMetadata = function(metadata, callback) {\n  var that = this;\n\n  if (metadata.name) {\n    metadata.friendlyName = metadata.name;\n    delete metadata.name;\n  }\n\n  if (util.is(metadata.schema, 'string')) {\n    metadata.schema = Table.createSchemaFromString_(metadata.schema);\n  }\n\n  this.makeReq_('PUT', '', null, metadata, function(err, resp) {\n    if (err) {\n      callback(err);\n      return;\n    }\n\n    that.metadata = resp;\n\n    callback(null, that.metadata);\n  });\n};\n\n/**\n * Pass through this request to BigQuery's request handler, first prepending the\n * path with the dataset.\n *\n * @private\n *\n * @param {string} method - Action.\n * @param {string} path - Request path.\n * @param {*} query - Request query object.\n * @param {*} body - Request body contents.\n * @param {function} callback - The callback function.\n */\nTable.prototype.makeReq_ = function(method, path, query, body, callback) {\n  path = '/tables/' + this.id + path;\n  this.dataset.makeReq_(method, path, query, body, callback);\n};\n\nmodule.exports = Table;",
    "ctx": {
      "type": "method",
      "constructor": "Table",
      "cons": "Table",
      "name": "import",
      "string": "Table.prototype.import()"
    }
  }
]